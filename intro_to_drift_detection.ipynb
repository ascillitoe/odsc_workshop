{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3efcd04f",
   "metadata": {
    "id": "6a288462"
   },
   "source": [
    "# ODSC 2022: An Introduction to Drift Detection\n",
    "\n",
    "To load this notebook in Google Colab [CLICK HERE](https://colab.research.google.com/github/ascillitoe/odsc_workshop/blob/main/intro_to_drift_detection.ipynb).\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this workshop, you'll learn about *drift detection* through a number of tasks:\n",
    "\n",
    "1. [Classifying newsgroups](#1.-Classifying-newsgroups) - you'll train a machine learning model to classify the topic of newsgroup posts.\n",
    "2. [Performance under drift](#2.-Performance-under-drift) - You'll examine the performance of your classifier on test data that has *drifted* from the data it was trained on.\n",
    "3. [Detecting drift](#3.-Detecting-drift) - You'll use the open-source [Alibi Detect](https://docs.seldon.io/projects/alibi-detect/en/latest/) library to detect a number of types of drift in a principled manner. \n",
    "4. [Accounting for context](#4.-Accounting-for-context) - To finish, you'll learn how to use a powerful drift detector which is able to take relevent context into account.\n",
    "\n",
    "We'll also leave you with some [homework](#Homework!) to cement your newfound knowledge. After this, you'll have a good working knowledge drift detection, and will be able to apply it to your own ML tasks!\n",
    "\n",
    "**Note:** This notebook has some sections left blank for you to fill in (marked with `???`). If you'd rather follow a completed notebook, this can be accessed [here](https://github.com/ascillitoe/odsc_workshop/blob/main/intro_to_drift_detection_master.ipynb), or loaded into Google Colab by [clicking here](https://colab.research.google.com/github/ascillitoe/odsc_workshop/blob/main/intro_to_drift_detection_master.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15aa76b1",
   "metadata": {
    "id": "bf3c9ceb"
   },
   "source": [
    "## 0. Getting ready\n",
    "\n",
    "This workshop relies on a number of files located in a [github repo](https://github.com/ascillitoe/odsc_workshop). If running locally, start by cloning the repo, and moving to the workshop directory:\n",
    "\n",
    "```\n",
    "git clone https://github.com/ascillitoe/odsc_workshop.git\n",
    "cd odsc_workshop\n",
    "```\n",
    "\n",
    "If running on Google Colab, the following code will fetch the necessary files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507974f5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "09fa8f99",
    "outputId": "76af0e96-cf70-402f-9964-2cabfd44e467"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    import zipfile\n",
    "    import shutil\n",
    "    import os\n",
    "\n",
    "    !wget -nc https://github.com/ascillitoe/odsc_workshop/archive/refs/heads/main.zip\n",
    "\n",
    "    pz = open('main.zip', 'rb')\n",
    "    packz = zipfile.ZipFile(pz)\n",
    "    packz.extractall()\n",
    "    pz.close()\n",
    "\n",
    "    srcdir = 'odsc_workshop-main/'\n",
    "    for filepath in os.listdir(srcdir):\n",
    "        if not os.path.exists(filepath):\n",
    "            shutil.copyfile(os.path.join(srcdir, filepath), filepath)\n",
    "    shutil.rmtree(srcdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5a4d63",
   "metadata": {
    "id": "e4617fcb"
   },
   "source": [
    "### Software\n",
    "\n",
    "In this workshop we'll make use of state-of-the-art drift detectors from the open-source [Alibi Detect](https://docs.seldon.io/projects/alibi-detect/en/latest/) library. To install Alibi Detect, and the other dependencies used in this workshop, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466d70bd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7b1f5060",
    "outputId": "ee1747c7-4c36-4785-8fb8-e9f6f194003e"
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf6f4c7",
   "metadata": {
    "id": "7f65feb2"
   },
   "source": [
    "### Download data and sentence transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df71af48",
   "metadata": {},
   "source": [
    "To download the [twenty newsgroups dataset](https://archive.ics.uci.edu/ml/datasets/Twenty+Newsgroups) and the [sentence transformer model](https://huggingface.co/sentence-transformers/paraphrase-MiniLM-L6-v2) (more on these later), run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8997a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "70af6555",
    "outputId": "418b4ac5-20aa-4c0d-ddd3-109c42988113"
   },
   "outputs": [],
   "source": [
    "# Fetch preqrequisites\n",
    "from workshop_utilities import fetch_prerequisites\n",
    "dataset, sentence_transformer = fetch_prerequisites()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b052fe58",
   "metadata": {
    "id": "43d2fd99"
   },
   "source": [
    "## 1. Classifying newsgroups\n",
    "\n",
    "### The data\n",
    "\n",
    "The dataset we'll explore in this workshop is the [20 newsgroup dataset](https://archive.ics.uci.edu/ml/datasets/Twenty+Newsgroups). [Usenet newsgroups](https://en.wikipedia.org/wiki/Usenet_newsgroup) have been around since the dawn of the internet, and can be thought of as the very first online social network! \n",
    "\n",
    "The dataset should contain about 18,000 newsgroup posts across 20 topics, including politics, science, sports and religion. Check this now! (*Note: The actual posts are stored in a list `dataset.data`, and a list of topic names is stored in `dataset.target_names`*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb40f101",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{len(dataset.data)} posts')\n",
    "print(f'{len(dataset.target_names)} categories:')\n",
    "classes = dataset.target_names\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c926c45",
   "metadata": {},
   "source": [
    "To get an idea of what a post looks like, print out an instance and it's topic (*Note: The topic labels are stored as integers in `dataset.targets`. These can be used to index `dataset.target_names`*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d45c9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0  # instance index\n",
    "post = dataset.data[i]\n",
    "topic_idx = dataset.target[i]\n",
    "topic = classes[topic_idx]\n",
    "\n",
    "print(post)\n",
    "print(f'Topic: {topic}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fa082d",
   "metadata": {},
   "source": [
    "So, each data instance looks something like an email. We wish to train a machine learning model that can take in future instances (without labels), and predict their topic. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b594e1c",
   "metadata": {
    "id": "9d27f700"
   },
   "source": [
    "### Visualising the embeddings\n",
    "\n",
    "For classification, we'll use a simple [MLP](https://en.wikipedia.org/wiki/Multilayer_perceptron) model. But before that, we'll transform the posts into *semantically meaningful sentence embeddings* (*semantically meaningful* means that semantically similar sentences are close in vector space).\n",
    "\n",
    "To extract embeddings, we'll use the pre-trained `'paraphrase-MiniLM-L6-v2'` model from the [SentenceTransformers](https://www.sbert.net/index.html) package. To see this model in action, you can checkout the [hosted HuggingFace API](https://huggingface.co/sentence-transformers/paraphrase-MiniLM-L6-v2). The `sentence_transformer` should already have been loaded earlier, so we just need to pass it to the `EmbeddingModel` wrapper class via the `model` kwarg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c268f0",
   "metadata": {
    "id": "1f5ea9e8"
   },
   "outputs": [],
   "source": [
    "from workshop_utilities import EmbeddingModel\n",
    "emb_model = EmbeddingModel(model=sentence_transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dd5093",
   "metadata": {},
   "source": [
    "The sentence embeddings are high dimensional (384-d to be precise!). To visualise them, we need to first reduce their dimensionality. For this, we will train a [UMAP](https://umap-learn.readthedocs.io/en/latest/) (Uniform Manifold Approximation and Projection) model. UMAP is able to take advantage of our data labels, so we'll need to pass it the data labels (from `dataset.target`) in addition to the embeddings.\n",
    "\n",
    "We won't need all of the 18000+ posts for training the UMAP model, so subsample the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924968f0",
   "metadata": {
    "id": "8a81218b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from workshop_utilities import set_seed\n",
    "set_seed(2022)  # This will ensure reproducibility (at least on CPU!)\n",
    "\n",
    "n_train = 2000  # A larger sample here will give a better UMAP projection, but can reduce if too slow\n",
    "\n",
    "idx_train = np.random.choice(len(dataset.data), size=n_train, replace=False)\n",
    "x_train, y_train = [dataset.data[_] for _ in idx_train], dataset.target[idx_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4be61ee",
   "metadata": {},
   "source": [
    "The list of training posts (`x_train`) is passed through the `emb_model` to transform them into embeddings. Print out the shape of `emb_train` here to check its dimensions (they should be `(n_train, 384)`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c360dd5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "593a8820",
    "outputId": "7b0237e5-0b1a-442a-a867-448a4b35ddba"
   },
   "outputs": [],
   "source": [
    "emb_train = emb_model(x_train)\n",
    "emb_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4768afd7",
   "metadata": {},
   "source": [
    "The UMAP model is provided for you in `workshop_utilities`. To train it, the embeddings `emb_train` and labels `y_train` are passed to the model's `.fit()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f106e3c6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e87b4ca5",
    "outputId": "0e9c2c70-943f-4e2a-d6f0-ea731eb38e22"
   },
   "outputs": [],
   "source": [
    "from workshop_utilities import UMAPModel\n",
    "umap_model = UMAPModel()\n",
    "umap_model.fit(emb_train, y=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c437444",
   "metadata": {},
   "source": [
    "Now use the UMAP model to obtain a 2-d representation `dr_train`of the 384-d embeddings `emb_train`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9e8200",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_train = umap_model.predict(emb_train)\n",
    "dr_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11740a36",
   "metadata": {},
   "source": [
    "We now have a 2-d representation of the sentence embeddings, from which we can visually inspect the various newsgroup topics. The `plot_clusters` utility function is provided for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b05b60a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "3606812e",
    "outputId": "cbb4c179-34b0-412c-8076-017be098b62f"
   },
   "outputs": [],
   "source": [
    "from workshop_utilities import plot_clusters\n",
    "plot_clusters(dr_train, y_train, classes, title='Training data: clustered news topics')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e46140",
   "metadata": {},
   "source": [
    "Hopefully your data is nicely clustered by topics! The clustering is partly down to the effectiveness of the sentence transformer in extracting semantically meaningful embeddings, but it is also aided by the UMAP algorithm which has a clustering effect when used in a supervised manner(see [here](https://umap-learn.readthedocs.io/en/latest/supervised.html#using-labels-to-separate-classes-supervised-umap))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f0ace8",
   "metadata": {
    "id": "799ebc30"
   },
   "source": [
    "### Training a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a44c27c",
   "metadata": {
    "id": "d394b2dc"
   },
   "source": [
    "Now to train a classifier!\n",
    "\n",
    "In the interests of time, the `Classifier` model has been defined for you in `workshop_utilities`. The classifier is initialised with the `EmbeddingModel` you initialised earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f4e02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from workshop_utilities import Classifier\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "clf = Classifier(embedding=emb_model).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b313c4e3",
   "metadata": {},
   "source": [
    "The `Classifier` consists of a pre-trained sentence transformer model (the model you passed to `embedding`), and an MLP head. These two components are stored in the attributes `.embedding_model` and `.head`. Print out the attributes to have a look for yourself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dde1353",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.embedding_model)\n",
    "print('')\n",
    "print(clf.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e931865",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "48f64f05",
    "outputId": "2c3e5148-6dbd-487d-8af0-18d85a673224"
   },
   "source": [
    "To demonstrate *drift*, we want to start by only training the classifer on posts from two topics; cryptology (11) and space (14). The utility function `split_data` splits a dataset with a specified number of instances per class (i.e. per topic). We can use this to generate *train* and *test* data consisting of only cryptology and space posts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6c7adb",
   "metadata": {
    "id": "98f3a16f"
   },
   "outputs": [],
   "source": [
    "from workshop_utilities import split_data\n",
    "\n",
    "n_classes = len(classes)\n",
    "n_train_c = [0] * n_classes  # Sample 0 from all topics (will update below!) \n",
    "n_test_c = [0] * n_classes\n",
    "\n",
    "n_train_c[11], n_train_c[14] = 200, 200  # subsample topics 11 & 14 only\n",
    "n_test_c[11], n_test_c[14] = 100, 100  # subsample topics 11 & 14 w/ sample proportions as above\n",
    "\n",
    "(x_train, y_train), (x_test, y_test), _ = split_data(dataset.data, dataset.target, n_train_c, n_test_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dab2e1",
   "metadata": {},
   "source": [
    "Check `y_train`, does it consist of only 11's and 14's?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029ba0fb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "deb8d8d2",
    "outputId": "90e326e7-7023-4f68-f7ce-8ed8e6a6439e"
   },
   "outputs": [],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463ab323",
   "metadata": {},
   "source": [
    "Use the `plot_clusters` function to visualise the training data. Is it as expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8711ecad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "bff64cbd",
    "outputId": "125facde-5b8d-4fdf-f877-ff1618401adf"
   },
   "outputs": [],
   "source": [
    "emb_train = emb_model(x_train)\n",
    "plot_clusters(emb_train, y_train, classes, dr_model=umap_model, title='Training data: clustered news topics')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c5f66a",
   "metadata": {},
   "source": [
    "If everything looks good, `x_train` and `y_train` can now be used to train the classifier! Note that training only involves the MLP head, the pre-trained embedding backbone is left untouched.\n",
    "\n",
    "In the interests of time, the classifier has actually been trained for you. If you'd rather perform the training yourself, set `TRAIN_CLF = True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7d97c6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9a679e3b",
    "outputId": "feec2a86-2365-42a1-b561-7509ff4146a6"
   },
   "outputs": [],
   "source": [
    "from workshop_utilities import train_model, eval_model\n",
    "\n",
    "TRAIN_CLF = False  # Set to TRUE to train classifier, otherwise it will be loaded from disk\n",
    "filepath = 'classifier'\n",
    "if TRAIN_CLF:\n",
    "    # Train model\n",
    "    train_model(clf, x_train, y_train, epochs=5, shuffle=True)\n",
    "    clf.eval()\n",
    "    # Save model\n",
    "    torch.save(clf.state_dict(), filepath)\n",
    "    # Check train and test accuracy\n",
    "    _, _ = eval_model(clf, x_train, y_train, shuffle=True)\n",
    "    _, _ = eval_model(clf, x_test, y_test, shuffle=True)\n",
    "else:\n",
    "    # Load model\n",
    "    clf.load_state_dict(torch.load(filepath, map_location=device))\n",
    "    clf = clf\n",
    "    clf.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ada9dd",
   "metadata": {
    "id": "b63002d4"
   },
   "source": [
    "### Testing the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0174d5",
   "metadata": {},
   "source": [
    "We can now run the classifier on previously unseen instances from the *test* set. If you use `plot_clusters` on the test set, you'll see that it's distribution is qualitatively similar to the *training set*; **the instances are drawn from the same distribution, but the instances are not the same**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17a7d4e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "6ddda901",
    "outputId": "c6ca43ee-5574-4894-e220-323ec12d80d5"
   },
   "outputs": [],
   "source": [
    "emb_test = emb_model(x_test)\n",
    "plot_clusters(emb_test, y_test, classes, dr_model=umap_model, title='Test data: clustered news topics')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d7c50e",
   "metadata": {
    "id": "0ef79da1"
   },
   "source": [
    "To convince yourself the classifier is working, you can run it on a few instances and examine its predictions (*Note: The classifier outputs logits, so we have to run .argmax(1) on the output to obtain a class prediction)*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d971576b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "c34d86d4",
    "outputId": "1f41a5a5-6537-4f18-ee79-ffb41ec77325"
   },
   "outputs": [],
   "source": [
    "idx = 42\n",
    "class_pred = clf([x_test[idx]]).argmax(1)\n",
    "classes[class_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ba85b7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ec4bf0c",
    "outputId": "bfd9eff6-14d9-46d6-b983-d33d91b4872e"
   },
   "outputs": [],
   "source": [
    "print(classes[y_test[idx]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8d33be",
   "metadata": {
    "id": "6cf7b6d3"
   },
   "source": [
    "## 2. Performance under drift\n",
    "\n",
    "To artificially introduce drift, lets now introduce a new topic into our test data. Use the `split_data` function to create two datasets:\n",
    "\n",
    "1. `(x_nodrift, y_nodrift)` - A data set with the same topic prevalence as the original test data.\n",
    "2. `(x_drift, y_drift)` - A data set with the same number of instances of topics 11 and 14, but also 100 instances of topic 18 (talk.politics.misc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0376ee",
   "metadata": {
    "id": "6efc6219"
   },
   "outputs": [],
   "source": [
    "n_classes = len(classes)\n",
    "n_nodrift_c = n_test_c\n",
    "n_drift_c = [0] * n_classes\n",
    "\n",
    "n_drift_c[11], n_drift_c[14], n_drift_c[18] = 100, 100, 100  # \n",
    "\n",
    "(x_nodrift, y_nodrift), (x_drift, y_drift), _ = split_data(dataset.data, dataset.target, n_nodrift_c, n_drift_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e666507",
   "metadata": {},
   "source": [
    "Use `plot_clusters` to check the new *_drift* data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df85dfe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "d8d21d87",
    "outputId": "b722ef58-a761-4e19-c780-ea26ccac728b"
   },
   "outputs": [],
   "source": [
    "emb_drift = emb_model(x_drift)\n",
    "plot_clusters(emb_drift, y_drift, classes, dr_model=umap_model, title='Drifted data: clustered news topics')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859ff7de",
   "metadata": {
    "id": "ef1c392e"
   },
   "source": [
    "It should be clear that the new `_drift` dataset distribution is quite different to the previous test data distribution, in that there is a new topic cluster. To see the effect of this *data drift* on our classifier, use the `eval_model` function on the *_nodrift* and *_drift* data sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d292fe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "535bc9e4",
    "outputId": "a894fe07-e757-4a47-cfbb-6133c11e1cdf"
   },
   "outputs": [],
   "source": [
    "_, _ = eval_model(clf, x_nodrift, y_nodrift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec9ec54",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dbebce6a",
    "outputId": "75268688-0f65-403e-8b31-4fab52051c3d"
   },
   "outputs": [],
   "source": [
    "_, _ = eval_model(clf, x_drift, y_drift)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfa2595",
   "metadata": {},
   "source": [
    "Unsurprisingly, the classifier does not perform well when a new topic not seen during training is introduced!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa93a4de",
   "metadata": {},
   "source": [
    "## 3. Detecting drift\n",
    "\n",
    "As you just did, if labels (e.g. `y_`) are available at test time, harmful drift can be detected by simply evaluating your ML model's performance. However, in deployment/production, labels often aren't available. What can we do to detect drift here?\n",
    "\n",
    "In the following sections you will use a number of different [Alibi Detect](https://docs.seldon.io/projects/alibi-detect/en/latest/) drift detectors to detect different types of drift. As you will discover, the general workflow is usually similar, with a preprocessing step, a statistical hypothesis test, and then a comparision of the resulting p-value to a certain threshold to decide if drift has occured.\n",
    "\n",
    "![odsc_pipeline.png](images/drift_detection_pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8700f882",
   "metadata": {
    "id": "a51888f2"
   },
   "source": [
    "### Detecting drift on the inputs\n",
    "\n",
    "The first type of drift we'll consider is input (covariate) drift. This is defined as $P(\\mathbf{X}) \\neq P(\\mathbf{X}_{ref})$, i.e. input drift is said to have occured when the distribution of the input data has changed.\n",
    "\n",
    "We can't apply a drift detector directly to the original data `x_`. Instead, we monitor the data in the embedding space. To start, we need a preprocessing function which will be applied to reference data (the data given to a detector at instantiation time) and test data (the data given to the detector's `.predict` method).\n",
    "\n",
    "This function should: \n",
    "- Accept a list of posts `x`.\n",
    "- Apply the classifier embedding model to transform `x` to the embedding space.\n",
    "- Return the embeddings as a ndarray.\n",
    "\n",
    "*Hint: the embedding model will return a `torch.Tensor`, but Alibi Detect expects `np.ndarray`'s, so you'll need to convert to this with `.cpu().numpy()`*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ee2758",
   "metadata": {
    "id": "2bbf345d"
   },
   "outputs": [],
   "source": [
    "def preprocess_fn(x: list):\n",
    "    x = ???\n",
    "    return ???"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b2e917",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>CLICK FOR SOLUTION</b></summary>\n",
    "\n",
    "    def preprocess_fn(x: list):\n",
    "        x = clf.embedding_model(x)\n",
    "        return x.cpu().numpy()\n",
    "\n",
    "</details>\n",
    "\n",
    "This is a good example of how you can often recycle components of your existing ML models to serve as the preprocessing stage of a drift detector. Now that you've defined the preprocessing stage, you can instantiate the actual drift detector.\n",
    "\n",
    "Import the `MMDDrift` detector from `alibi_detect.cd`, and set the following args and kwargs (see the [MMDDrift docs](https://docs.seldon.io/projects/alibi-detect/en/latest/cd/methods/mmddrift.html) for a full list of kwargs):\n",
    "\n",
    "- The first arg is expected to be a np.ndarray or list of reference data. This is the data we will compare to at predict time i.e. usually it will be from the same data distribution used to train the model. As a general rule, you shouldn't use the exact model training data as reference data, so instead, use the held-out `x_test` data.\n",
    "- Set the `backend` kwarg to `'pytorch'`, since our classifier is a PyTorch model (the default is `'tensorflow'`).\n",
    "- Set `p_val` to a decimal of your choice (the default is `0.05`). This is the p-value threshold below which we flag drift. \n",
    "- Pass your preprocess function defined above to `preprocess_fn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe09d4e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "db4aea0e",
    "outputId": "2d098717-e6c3-4168-cc6e-b88d933510ee"
   },
   "outputs": [],
   "source": [
    "from ??? import ???\n",
    "x_ref = ???\n",
    "dd = MMDDrift(x_ref, backend=???, p_val=???, preprocess_fn=???)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ff7413",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>CLICK FOR SOLUTION</b></summary>\n",
    "\n",
    "    from alibi_detect.cd import MMDDrift\n",
    "    x_ref = x_test\n",
    "    dd = MMDDrift(x_ref, backend='pytorch', p_val=.05, preprocess_fn=preprocess_fn)\n",
    "\n",
    "</details>\n",
    "\n",
    "Now the detector is ready to be used! Pass the `x_nodrift` data to `.predict()` to check if this data has drifted from `x_ref`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9784fe85",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "80db1111",
    "outputId": "f7c99ed3-82ef-49ef-f807-97a384080541"
   },
   "outputs": [],
   "source": [
    "dd.??(??)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9177a685",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>CLICK FOR SOLUTION</b></summary>\n",
    "\n",
    "    dd.predict(x_nodrift)\n",
    "\n",
    "</details>\n",
    "\n",
    "The `predict` method returns a dictionary with the relevent predict info stored under `'data'`. The important field for us is `is_drift`, which equals `0` if no drift is detected (i.e. `'p_val'` $>$ `'threshold'`), and equals `1` if drift is detected (i.e. `'p_val'` $\\le$ `'threshold'`).\n",
    "\n",
    "Hopefully drift isn't detected above (`is_drift = 0`), meaning we have failed to reject $H_0: P(\\mathbf{X}) = P(\\mathbf{X}_{ref})$. Note that you might flag drift here sometimes, as a perfectly calibrated detector will still return the occasional false positive (we discuss this [later](#Important-note!)).\n",
    "\n",
    "Now, try the same for `x_drift`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ad2f46",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "57005484",
    "outputId": "5f955430-ae9e-4878-b659-021f25a8c534"
   },
   "outputs": [],
   "source": [
    "dd.??(??)['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc31733b",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>CLICK FOR SOLUTION</b></summary>\n",
    "\n",
    "    dd.predict(x_drift)['data']\n",
    "\n",
    "</details>\n",
    "\n",
    "\n",
    "Hopefully, drift is detected! If it is, this means there is enough evidence to reject $H_0$ and flag drift (although sometimes it might be missed, unless the detector's [test power](https://en.wikipedia.org/wiki/Power_of_a_test) is 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe533d5b",
   "metadata": {},
   "source": [
    "### Detecting drift on the outputs (optional!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cc5f8f",
   "metadata": {},
   "source": [
    "The next type of drift we'll consider is output (prior) drift. This is defined as $P(\\mathbf{Y}) \\neq P(\\mathbf{Y}_{ref})$, i.e. output drift is said to have occured when the distribution of the output data (labels) has changed.\n",
    "\n",
    "If you have access to labels `y_` you can monitor output drift by passing them directly to the detector (you can try this!). When labels are not available, the ML model's outputs can be used as a proxy for the true labels, as is done below:\n",
    "\n",
    "*Note: You can either use the classifier's logits output, or its class predictions.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca13c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_fn(x: list):\n",
    "    x = clf(x)\n",
    "    return x.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e38077",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = MMDDrift(x_ref, backend='pytorch', p_val=.05, preprocess_fn=preprocess_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67817bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.predict(x_nodrift)['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a47a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.predict(x_drift)['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea12f23",
   "metadata": {
    "id": "7ad48493"
   },
   "source": [
    "### Detecting model drift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bb22ad",
   "metadata": {
    "id": "4a0e48b9"
   },
   "source": [
    "A downside (or upside!) of monitoring input/output drift is it doesn't tell you if the drift is likely to be harmful to your ML model. An alternative approach is to use a model uncertainty based detector such as the [ClassifierUncertaintyDrift](https://docs.seldon.io/projects/alibi-detect/en/latest/cd/methods/modeluncdrift.html) detector. This tests for a change in the number of instances falling into regions of the input space on which the model is uncertain in its predictions. \n",
    "\n",
    "Define your `ClassifierUncertaintyDrift` detector with the following args and kwargs:\n",
    "\n",
    "- Again, the first arg should be the reference data.\n",
    "- The second arg should be the ml model used to obtain uncertainties. Since our classifier provides a notion of uncertainty (the logits), this can be used directly.\n",
    "- Set the `backend` and `p_val` kwargs.\n",
    "- Check the [ClassifierUncertaintyDrift](https://docs.seldon.io/projects/alibi-detect/en/latest/cd/methods/modeluncdrift.html) docs to see what to set `preds_type` to.\n",
    "- Set `preprocess_batch_fn=clf.embedding_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c950d8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0b17b8f3",
    "outputId": "6ea4cbcd-fc19-4194-ea98-eb2e37005d31"
   },
   "outputs": [],
   "source": [
    "from alibi_detect.cd import ???\n",
    "\n",
    "\n",
    "dd = ClassifierUncertaintyDrift(???, ???, \n",
    "                                preprocess_batch_fn=???, backend='pytorch', \n",
    "                                p_val=.05, preds_type=???)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc472513",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>CLICK FOR SOLUTION</b></summary>\n",
    "\n",
    "    from alibi_detect.cd import ClassifierUncertaintyDrift\n",
    "\n",
    "    dd = ClassifierUncertaintyDrift(x_ref, clf, \n",
    "                                    preprocess_batch_fn=clf.embedding_model, backend='pytorch', \n",
    "                                    p_val=.05, preds_type='logits')\n",
    "\n",
    "</details>\n",
    "\n",
    "Once instantiated, you should be able to make predictions on `x_nodrift` and `x_drift`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09582f60",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "26423a3f",
    "outputId": "ff80f477-cf5f-407f-ae20-882c7fc4876b"
   },
   "outputs": [],
   "source": [
    "dd.predict(x_nodrift)['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ced5426",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "005cff42",
    "outputId": "c0913742-0c3d-4761-849b-b9ff5b27ef46"
   },
   "outputs": [],
   "source": [
    "dd.predict(x_drift)['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162d36a7",
   "metadata": {
    "id": "a6c7e40a"
   },
   "source": [
    "## 4. Accounting for context\n",
    "\n",
    "So far, **we have assumed that both the reference and test data are [i.i.d.](https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables) samples from their underlying distributions**. However, in some *real world* scenarios this assumption doesn't hold. \n",
    "\n",
    "For example, consider the case where we have trained our classifier on a training set consisting of all twenty topics (to ensure the classifier sees a diverse range of posts during training). Now, imagine that we wish to use the classifier whilst the World Series and Stanley Cup are occuring, leading to a spike in news posts on baseball and hockey respectively. Furthermore, there is not too much news on Mac or Windows since there are no new releases or products planned anytime soon. Crucially, the distribution underlying each subpopulation (e.g. the distribution of *hockey* news itself) remains unchanged, therefore the classifier should still work well in this scenario. However, since the relative frequency of one or more subpopulations (i.e. news topics) has changed, if we assume the test instances are i.i.d (i.e. we use the standard `MMDDrift` detector), then we will detect drift.\n",
    "\n",
    "To ensure that drift isn't flagged when the distribution underlying each subpopulation is unchanged, we need a way to provide our drift detector with relevent context (*conditioning*) information.\n",
    "\n",
    "### Generate some example data\n",
    "\n",
    "We can use the `split_data` to generate some data matching the scenario described above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a99c046",
   "metadata": {
    "id": "43ee261b"
   },
   "outputs": [],
   "source": [
    "n_classes = len(classes)\n",
    "n_nochange_c = 1000 // n_classes  # equally subsample each class from 1000 instances\n",
    "\n",
    "n_change_c = [50] * n_classes  # 50 of each class (so 1000 in total), but then mod. below.\n",
    "n_change_c[4], n_change_c[5] = 5, 5  # few stories on Mac/Windows\n",
    "n_change_c[9], n_change_c[10] = 95, 95  # more stories on baseball/hockey\n",
    "\n",
    "(x_nochange, y_nochange), (x_change, y_change), (x_train, y_train) = split_data(dataset.data, dataset.target, \n",
    "                                                                      n_nochange_c, n_change_c, seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144e7d50",
   "metadata": {},
   "source": [
    "Three sets of data have been generated:\n",
    "\n",
    "- `_nochange`: Data equally subsampled from all 20 subpopulations (topics) - *Used as reference data*.\n",
    "- `_change`: Data with the prevalence of some subpopulations/topics changed - *We'll monitor this for drift*.\n",
    "- `_train`: Held-out data with the same subpopulation prevalence as `_nochange` - *Used for training the classifier*.\n",
    "\n",
    "Visualise the `no_change` embeddings. You should now see all clusters for all 20 topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc9cc0d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "6e7f68ad",
    "outputId": "dd0cec8f-eb4f-4215-b77f-9b1af0ce91a7"
   },
   "outputs": [],
   "source": [
    "emb_nochange = emb_model(x_nochange)\n",
    "plot_clusters(emb_nochange, y_nochange, classes, dr_model=umap_model, title='Reference data: clustered news topics')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bf7c3b",
   "metadata": {
    "id": "7aa6b2c9"
   },
   "source": [
    "### Vanilla MMD detector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd9fb25",
   "metadata": {},
   "source": [
    "Before looking at context-aware drift detection, lets see how the standard `MMDDrift` detector performs here. To save a bit of time, the embeddings are pre-computed and passed straight to the detector (so that `preprocess_fn` doesn't have to be called for both detectors). \n",
    "\n",
    "For the reference data `emb_ref`, the `emb_nochange` embeddings computed previously are used. To save time, the ndarray `emb_change` is also computed here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83532fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_ref = emb_nochange.cpu().numpy()\n",
    "emb_change = emb_model(x_change).cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1b3cf1",
   "metadata": {},
   "source": [
    "Now init an `MMDDrift` detector, and use it to check for drift on `emb_change`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa510b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = MMDDrift(emb_ref, p_val=0.05, backend='pytorch', n_permutations=100)\n",
    "dd.predict(emb_change)['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f93eec",
   "metadata": {
    "id": "520b3e80"
   },
   "source": [
    "You should find that drift is consistently flagged. This is expected since the vanilla MMD detector cannot take any external context into account and correctly detects that the reference and test data do not follow the same underlying distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b485ff",
   "metadata": {},
   "source": [
    "However, since the underlying distributions of the subpopulations are unchanged, a classifier trained on the full `x_train` should still work well on `x_change` (relative to `x_nochange`). This can be seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfd02cc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f7f21ff6",
    "outputId": "cd98a551-6ec3-4e46-fdcb-040a99a13136"
   },
   "outputs": [],
   "source": [
    "n_train = 2000\n",
    "idx_train = np.random.choice(len(x_train), size=n_train, replace=False)\n",
    "x_train, y_train = [x_train[_] for _ in idx_train], y_train[idx_train]\n",
    "\n",
    "TRAIN_CLF = False  # Set to TRUE to train classifier, otherwise it will be loaded from disk\n",
    "filepath = 'classifier_full'\n",
    "if TRAIN_CLF:\n",
    "    # init model\n",
    "    clf_full = Classifier().to(device)\n",
    "\n",
    "    # Train model\n",
    "    train_model(clf_full, x_train, y_train, epochs=5, shuffle=True)\n",
    "    clf_full.eval()\n",
    "    \n",
    "    # Save model\n",
    "    torch.save(clf_full.state_dict(), filepath)\n",
    "else:\n",
    "    # Load model\n",
    "    clf_full = Classifier()\n",
    "    clf_full.load_state_dict(torch.load(filepath, map_location=device))\n",
    "    clf_full = clf_full.to(device)\n",
    "    clf_full.eval()\n",
    "\n",
    "_, _ = eval_model(clf_full, x_nochange, y_nochange)\n",
    "_, _ = eval_model(clf_full, x_change, y_change)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df2e754",
   "metadata": {},
   "source": [
    "You should see a similar classification accuracy for the `_nochange` and `_change` cases above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bc68e9",
   "metadata": {
    "id": "58c29960"
   },
   "source": [
    "### Context aware MMD detector\n",
    "\n",
    "We want to monitor whether the underlying distribution of each subpopulation has drifted, given the topic label of that subpopulation. In other words, **we wish to provide the posts' topics as context**. Since we don't have access to the true labels at test time, we instead **condition on the prediction probabilities of the classifier**. \n",
    "\n",
    "First, define a function `context` to:\n",
    "\n",
    "- Take the raw embeddings `emb`. \n",
    "- Compute the `logits` with the classifier (*Hint: We need the classifier to be reasonably accurate, so remember to use the classifier trained on all 20 newsgroups*)\n",
    "- Take the `logits`, and return an *ndarray* of prediction probabilities. (*Hint: you'll need the [softmax](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html) function for this.*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23eca6c3",
   "metadata": {
    "id": "b5b5f6a1"
   },
   "outputs": [],
   "source": [
    "def context(???):\n",
    "    \"\"\" Condition on classifier prediction probabilities. \"\"\"\n",
    "    logits = ???(???).detach()  # Important classifier trained on full dataset used here!\n",
    "    softmax_fn = torch.nn.Softmax(dim=-1)\n",
    "    return softmax_fn(???).cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb582a9",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>CLICK FOR SOLUTION</b></summary>\n",
    "\n",
    "    def context(emb):\n",
    "        \"\"\" Condition on classifier prediction probabilities. \"\"\"\n",
    "        logits = clf_full(emb).detach()  # Important classifier trained on full dataset used here!\n",
    "        softmax_fn = torch.nn.Softmax(dim=-1)\n",
    "        return softmax_fn(logits).cpu().numpy()\n",
    "\n",
    "</details>\n",
    "\n",
    "Now you're ready to define your [ContextMMDDrift](https://docs.seldon.io/projects/alibi-detect/en/latest/cd/methods/contextmmddrift.html) detector. Define it with the following args/kwargs:\n",
    "\n",
    "- arg 1: The reference data, as usual. You can use `emb_ref` for this.\n",
    "- arg 2: The context associated with the reference data. For this you can use your `context` function to transform `emb_ref`.\n",
    "- `p_val` and `backend` kwargs as usual.\n",
    "- Set `n_permutations=100` to match the `MMDDrift` detector's default (this usually defaults to 1000 for the `ContextMMDDrift`). This kwarg's controls how many permutations are used to compute the p-value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a5cb45",
   "metadata": {
    "id": "60c8f1ca"
   },
   "outputs": [],
   "source": [
    "from alibi_detect.cd import ContextMMDDrift\n",
    "dd_cad = ContextMMDDrift(???, ???, p_val=.05, n_permutations=100, backend='pytorch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44de12a8",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>CLICK FOR SOLUTION</b></summary>\n",
    "\n",
    "    from alibi_detect.cd import ContextMMDDrift\n",
    "    dd_cad = ContextMMDDrift(emb_ref, context(emb_ref), p_val=.05, n_permutations=100, backend='pytorch')\n",
    "\n",
    "</details>\n",
    "\n",
    "Now you're ready to use the detector! Try it out on the `emb_nochange` and `emb_change` data sets (*Hint: You must give the `ContextMMDDrift.predict()` method context associated with the test data*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a9d872",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_cad.predict(???, ???)['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201b3c4f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c79c5ea2",
    "outputId": "3d0be038-5983-4188-97fa-dab17ef4f89d"
   },
   "outputs": [],
   "source": [
    "dd_cad.predict(???, ???)['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1011fd87",
   "metadata": {
    "id": "89f02c43"
   },
   "source": [
    "<details>\n",
    "<summary><b>CLICK FOR SOLUTION</b></summary>\n",
    "\n",
    "    dd_cad.predict(emb_nochange, context(emb_nochange))['data']\n",
    "    dd_cad.predict(emb_change, context(emb_change))['data']\n",
    "</details>\n",
    "\n",
    "Hopefully drift isn't detected! We don't expect the context-aware detector to consistently flag drift, as the change in frequency of news topics is permissible given the context provided.\n",
    "\n",
    "### Important note!\n",
    "\n",
    "We've been a bit vauge with the word \"*consistently*\" above. When run many times under *no-drift*, a perfectly calibrated detector should return a uniform distribution of p-values $\\mathcal{U}\\left[0,1\\right]$. Therefore, if you chose a p-value threshold of 0.05, you'd expect a false positive detection 5% of the time. In practice, to quantify how well calibrated a detector is, it must be run many times so that the p-value distribution under no-drift can obtained.\n",
    "\n",
    "Below is the p-value distribution under no-drift for the context aware detector. As you can see, it is relatively well calibrated. For homework, you can generate these plots yourself for the standard and context-aware detectors!\n",
    "\n",
    "![contextMMD_calibration.png](images/contextMMD_calibration.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75ddaaa",
   "metadata": {
    "id": "33d1d5bb"
   },
   "source": [
    "## Homework!\n",
    "\n",
    "To learn more about drift detection, below are a number of topics you can explore in your own time.\n",
    "\n",
    "### Examining detector calibration and test power\n",
    "\n",
    "The performance of a drift detector can be quantified by measuring its:\n",
    "\n",
    "- **calibration**: The distribution of calculated p-values when there is no drift. For a perfectly calibrated detector, we expect the p-values to be uniformly distributed under $U[0,1]$ when there is no drift.\n",
    "\n",
    "- [**test power**](https://en.wikipedia.org/wiki/Power_of_a_test): probability of a \"true positive\" when drift is present, i.e. correctly rejecting the null hypothesis (with the null hypothesis being that there is no drift).\n",
    "\n",
    "To measure the above quantities, we must run many experiments, instantiating detectors and making predictions on many random splits of data. To measure the calibration of the standard and context drift detectors from [section 4](#4.-Accounting-for-context) we set up the same datasets used previously. Since we need to run multiple experiments on different splits, we increase the size of the data splits to 5000 instances.\n",
    "\n",
    "*Note: We are measuring* ***calibration*** *here, since we have set up a scenario where we don't expect drift (given the context!). You can measure* ***test power*** *in a similar way, by measuring the proportion of true positives in a scenario where you do expect drift (see this [Alibi Detect example](https://docs.seldon.io/projects/alibi-detect/en/stable/examples/cd_context_20newsgroup.html#Changing-the-subpopulation-distribution)).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c153b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(classes)\n",
    "n_nochange_c = 5000 // n_classes  # equally subsample each class from 5000 instances\n",
    "\n",
    "n_change_c = [250] * n_classes  # 250 of each class (so 5000 in total), but then mod. below.\n",
    "n_change_c[4], n_change_c[5] = 50, 50  # few stories on Mac/Windows\n",
    "n_change_c[9], n_change_c[10] = 450, 450  # more stories on baseball/hockey\n",
    "\n",
    "(x_nochange, y_nochange), (x_change, y_change), _ = split_data(dataset.data, dataset.target, \n",
    "                                                               n_nochange_c, n_change_c, seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cb65a2",
   "metadata": {},
   "source": [
    "Before we set off our experiments, we compute all necessary embeddings and contexts so we don't have to run the embedding model on every loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d94bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_nochange = emb_model(x_nochange).cpu().numpy()\n",
    "emb_change = emb_model(x_change).cpu().numpy()\n",
    "c_nochange = context(emb_nochange) \n",
    "c_change = context(emb_change)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28d1120",
   "metadata": {},
   "source": [
    "We're now ready to run the experiments! On each loop we re-split the `_nochange` and `_change` datasets, init new detectors, and make predictions. If it is taking too long you can reduce `n_runs`, however too few runs will result in a noisy p-value distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38688f76",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QulWdDXcGnsg",
    "outputId": "d7395981-c1d4-4207-ebdd-2a01877da91b"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "n_runs = 100\n",
    "n_drift = 1000\n",
    "p_vals_mmd = []\n",
    "p_vals_cad = []\n",
    "for run in tqdm(range(n_runs)):\n",
    "    rng = np.random.default_rng(run)\n",
    "    idx = rng.choice(len(x_nochange), size=n_drift, replace=False)  # assumes nochange and change are same len!\n",
    "\n",
    "    emb_ref = emb_nochange[idx]\n",
    "    emb_predict = emb_change[idx]\n",
    "    c_ref = c_nochange[idx]\n",
    "    c_predict = c_change[idx]\n",
    "    \n",
    "    dd_mmd = MMDDrift(emb_ref, p_val=0.05, n_permutations=100, backend='pytorch')\n",
    "    pred_mmd = dd_mmd.predict(emb_predict)\n",
    "    p_vals_mmd.append(pred_mmd['data']['p_val'])\n",
    "\n",
    "    dd_cad = ContextMMDDrift(emb_ref, c_ref, p_val=.05, n_permutations=100, backend='pytorch')\n",
    "    pred_cad = dd_cad.predict(emb_predict, c_predict)\n",
    "    p_vals_cad.append(pred_cad['data']['p_val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5722b4d",
   "metadata": {},
   "source": [
    "The computed p-value distributions can be visualised with a histogram plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8580dc1f",
   "metadata": {
    "id": "c6b9abcf"
   },
   "outputs": [],
   "source": [
    "from workshop_utilities import plot_hist\n",
    "\n",
    "p_vals_mmd = np.array(p_vals_mmd)\n",
    "p_vals_cad = np.array(p_vals_cad)\n",
    "\n",
    "p_vals = [p_vals_mmd, p_vals_cad]\n",
    "title = 'p-value distribution for a change in subpopulation prevalence'\n",
    "plot_hist(p_vals, title, ylim=(0,0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb34287",
   "metadata": {
    "id": "f715dbda"
   },
   "source": [
    "or we can use [Q-Q (Quantile-Quantile) plots](https://en.wikipedia.org/wiki/Q%E2%80%93Q_plot):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa58e10c",
   "metadata": {
    "id": "c5b40539"
   },
   "outputs": [],
   "source": [
    "from workshop_utilities import plot_qq\n",
    "plot_qq(p_vals_mmd, 'Q-Q plot MMD detector')\n",
    "plot_qq(p_vals_cad, 'Q-Q plot Context-Aware MMD detector')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a3ae31",
   "metadata": {
    "id": "6734e435"
   },
   "source": [
    "A perfectly calibrated detector should have a Q-Q plot which closely follows the diagonal. Only the middle plot in the grid shows the detector's p-values. The other plots correspond to *n_runs* p-values actually sampled from $U[0,1]$ to contextualise how well the central plot follows the diagonal given the limited number of samples.\n",
    "\n",
    "\n",
    "Both plots should show that the context-aware MMD detector is well-calibrated, but the normal MMD isn't! The normal MMD detector should consistently flag drift due to the change in subpopulation prevalence. The context aware drift detector should behave as if there is no drift, since  the change in subpopulation prevalence is permissible given the context provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a30bcf",
   "metadata": {},
   "source": [
    "### Speeding things up!\n",
    "\n",
    "The MMD detector and context-aware MMD detector can take some time to run on large datasets. As discussed [here](https://docs.seldon.io/projects/alibi-detect/en/stable/cd/background.html#dimension-reduction), one solution is to add a dimension reduction step to a detector's `preprocess_fn`. For example, in this Alibi Detect [IMDB text example](https://docs.seldon.io/projects/alibi-detect/en/stable/examples/cd_text_imdb.html#MMD-PyTorch-detector), an Untrained Auto Encoder (UAE) is used to further reduce the 768-dimensional text embedding space to a 32-d space. Applying drift detectors in this lower dimensional space is a good way to speed things up. For an advanced homework task, you can try adding a dimension reduction step to the preprocessors used in this workshop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b29f1ee",
   "metadata": {
    "id": "a64453f6"
   },
   "source": [
    "### Delving deeper into context-aware drift detection\n",
    "\n",
    "If the distribution of the subpopulations changes (instead of just the frequency), we would now expect the context-aware detector to flag drift. You can check this for yourself by adopting the dataset used in this Alibi Detect [newsgroups example](https://docs.seldon.io/projects/alibi-detect/en/stable/examples/cd_context_20newsgroup.html#Changing-the-subpopulation-distribution).\n",
    "\n",
    "We've only touched the surface of context-aware drift detection today. The detector can be applied to many different tasks by changing the context that is supplied. For more details, see the [ContextMMDDrift docs](https://docs.seldon.io/projects/alibi-detect/en/stable/cd/methods/contextmmddrift.html), the [newsgroup example](https://docs.seldon.io/projects/alibi-detect/en/stable/examples/cd_context_20newsgroup.html), and the [ecg example](https://docs.seldon.io/projects/alibi-detect/en/stable/examples/cd_context_ecg.html).\n",
    "\n",
    "\n",
    "### Interpretability of detections\n",
    "\n",
    "Sometimes you might want to interpret your drift detections in order to understand why drift is occuring. There are a number of things you can explore here:\n",
    "\n",
    "- **Feature-level attribution**: Some of the detectors listed [here](https://docs.seldon.io/projects/alibi-detect/en/stable/overview/algorithms.html) return a p-value for each feature, meaning you can attribute a drift detection to certain features. \n",
    "- **Instance-level attribution**: Some detectors, such as [ClassifierDrift](https://docs.seldon.io/projects/alibi-detect/en/stable/cd/methods/classifierdrift.html) return instance-level predictions, allowing you to attribute drift to certain instances.\n",
    "- **Detectors designed for interpretability**: The [SpotTheDiff](https://docs.seldon.io/projects/alibi-detect/en/stable/cd/methods/spotthediffdrift.html) detector is specifically designed to give detections that are interpretable at the feature level when they occur.\n",
    "\n",
    "If you follow the \"Examples\" links at the bottom of each drift detector docs page, you can explore how some of the above capability can be used. We are also working on detection methods which take advantage of our ML interpretability library [Alibi Explain](https://docs.seldon.io/projects/alibi/en/latest/), so watch this space!\n",
    "\n",
    "### Online drift detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6ecfd0",
   "metadata": {},
   "source": [
    "A final thing we haven't covered today is \"online\" drift detection. The describes the scenario when test instances arrive sequentially instead of in batches. In such a scenario it is important for the detector to be well calibrated (we desire a certain Expected Run Time in the absense of drift), yet it flag drift quickly when it is present. Alibi Detect offers a number of state-of-the-art [online detectors](https://docs.seldon.io/projects/alibi-detect/en/stable/cd/methods.html#online) that are designed to meet these requirements. For more info, see [this paper](https://arxiv.org/abs/2108.00883) and a related YouTube video: [Protecting Your Machine Learning Against Drift: An Introduction](https://www.youtube.com/watch?v=tL5sEaQha5o).\n",
    "\n",
    "The syntax for the online detectors is consistent with the offline detectors used in this workshop:\n",
    "\n",
    "```python\n",
    "# Init detector\n",
    "from alibi_detect.cd import MMDDriftOnline\n",
    "detector = MMDDriftOnline(x_ref, ERT, W, backend='pytorch', preprocess_fn=encoder_fn)\n",
    "\n",
    "# Make a prediction on a test instance\n",
    "detector.predict(x)\n",
    "```\n",
    "\n",
    "For a good example, check out the [medical imaging example](https://docs.seldon.io/projects/alibi-detect/en/stable/examples/cd_online_camelyon.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233a560d",
   "metadata": {},
   "source": [
    "## Follow-up questions\n",
    "\n",
    "Any follow-up questions or problems? Please feel free to get in touch at ashley.scillitoe@seldon.io "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Copy of intro_to_drift_detection_master.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
